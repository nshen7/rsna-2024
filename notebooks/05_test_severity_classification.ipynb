{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066b7d96-3b0f-4afa-b85c-73513fe57a3f",
   "metadata": {},
   "source": [
    "# Contents\n",
    "<div style=\"font-size: 16px;\">\n",
    "    This notebook evaluates how trained severity classification models perform on test sets, with respect to each spinal diagnosed condition.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7230612f-68d8-4ef3-820f-f12603ace3e7",
   "metadata": {},
   "source": [
    "# Install libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe3df4c-221a-479e-a317-a33b85f753cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pydicom -q\n",
    "!pip install torch==2.1 torchvision==0.16 -q\n",
    "!pip install -qU pycocotools\n",
    "!pip install -qU wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e7b73-ca8e-4bf8-964d-742edf8e46e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555dbf93-7458-489f-9f7a-9d5837ad3e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name in list(globals()):\n",
    "    if not name.startswith(\"_\"):  # Avoid deleting built-in and special variables\n",
    "        del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f59c29c-73b1-4a35-842e-6f9e0b79221d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f800d7cb-6ce5-4413-af4b-3265818479b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c462b-f66e-4bf8-ab25-a51f7f48d70a",
   "metadata": {},
   "source": [
    "## Install and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af99ab1-86ea-4996-9934-4aead5c24d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab701a8-b847-46b5-939c-bb3ca1a553a3",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124711f7-d98e-4ab4-940f-0650a43a782c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "PROJECT_DIR = '/home/jupyter'\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "SRC_DIR = os.path.join(PROJECT_DIR, 'src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d2f03-edf8-4c5d-b087-1d30ce33c975",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63c6e15-77ce-45d7-b7e4-4ec0c9889484",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SRC_DIR, 'pipeline_severity_classification.py')) as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471a269-0827-4d47-8cc4-cd83cbf7373d",
   "metadata": {},
   "source": [
    "# Evaluation on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c015af0-1dab-41ae-8131-bf55cbff436a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    total_loss = 0\n",
    "    n_examples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            n_examples += len(images)\n",
    "            # print(n_examples, loss)\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_preds.extend(preds.tolist())\n",
    "\n",
    "\n",
    "    # Calculate average test loss\n",
    "    avg_loss = total_loss / len(loader)\n",
    "\n",
    "    # Calculate accuracy, precision, and recall for the validation set\n",
    "    accuracy, precision, recall, f1 = accuracy_metrics(all_labels, all_preds)\n",
    "\n",
    "    # Print validation metrics\n",
    "    print(f\"Validation Metrics:\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy * 100:.2f}%\")\n",
    "    for cls in range(num_classes):\n",
    "        print(f\"  Class {cls}: Precision: {precision[cls]:.4f}, Recall: {recall[cls]:.4f}, F1-score: {f1[cls]:.4f}\")\n",
    "    \n",
    "    return n_examples, avg_loss, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9e90a0e-f7e2-464e-9dbd-536465567ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS_DICT = {\n",
    "    1: \"L1_L2\",\n",
    "    2: \"L2_L3\",\n",
    "    3: \"L3_L4\",\n",
    "    4: \"L4_L5\",\n",
    "    5: \"L5_S1\"\n",
    "}\n",
    "\n",
    "def evaluate_on_test_set(condition, epoch):\n",
    "    \n",
    "    MODEL_DIR = os.path.join(PROJECT_DIR, 'models', '04_train_severity_classification', condition)\n",
    "\n",
    "    # Read in metadata\n",
    "    test_df = pd.read_csv(os.path.join(DATA_DIR, 'processed_metadata', condition, 'test.csv'))\n",
    "    \n",
    "    if 'SubarticularStenosis' in condition:\n",
    "        dataset_test = RSNAUncroppedImageDataset(test_df)\n",
    "    else: \n",
    "        # Write cropped test images\n",
    "        crop_dir = os.path.join(DATA_DIR, 'test_crops', '03_test_disc_detection', condition)\n",
    "        filepaths = [os.path.join(crop_dir, f\"{row['study_id']}/{row['series_id']}/{LABELS_DICT[row['level_code']]}/{row['instance_number']}.pt\") for _, row in test_df.iterrows()]\n",
    "        test_df['cropped_image_path'] = filepaths\n",
    "        # Set dataset\n",
    "        dataset_test = RSNACroppedImageDataset(test_df)\n",
    "        \n",
    "    # Create data loder\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset_test,\n",
    "        batch_size=50,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Load model\n",
    "    trained_model = load_model_severity_classification(state_dict=torch.load(os.path.join(f\"{MODEL_DIR}/epoch_{epoch}/model_dict.pt\"))).to(device)\n",
    "    \n",
    "    # Load criterion\n",
    "    class_weights = torch.tensor([1.0, 2.0, 4.0]).clone().detach()  # Adjust weights as needed\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    return evaluate(trained_model, test_loader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81bd104-c549-4026-b16f-642cbd9695ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spinal Canal Stenosis (captured by Sagittal T2/STIR images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eba527fd-ad21-4e2a-ae0e-31cf11e29fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Loss: 0.3682\n",
      "  Accuracy: 90.64%\n",
      "  Class 0: Precision: 0.9695, Recall: 0.9605, F1-score: 0.9650\n",
      "  Class 1: Precision: 0.4123, Recall: 0.4352, F1-score: 0.4234\n",
      "  Class 2: Precision: 0.5634, Recall: 0.6154, F1-score: 0.5882\n"
     ]
    }
   ],
   "source": [
    "CONDITION = 'SpinalCanalStenosis'\n",
    "BEST_EPOCH = 3\n",
    "results_0 = evaluate_on_test_set(condition = CONDITION, epoch = BEST_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150bf07-fe03-4c07-96e5-fa61fc575b1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Left Neural Foraminal Narrowing (captured by Sagittal T1 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa0a7a00-40ec-4a97-ba5c-63f0468f0d97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Loss: 0.6593\n",
      "  Accuracy: 82.03%\n",
      "  Class 0: Precision: 0.8926, Recall: 0.9159, F1-score: 0.9041\n",
      "  Class 1: Precision: 0.5315, Recall: 0.4945, F1-score: 0.5123\n",
      "  Class 2: Precision: 0.5349, Recall: 0.4259, F1-score: 0.4742\n"
     ]
    }
   ],
   "source": [
    "CONDITION = 'LeftNeuralForaminalNarrowing'\n",
    "BEST_EPOCH = 4\n",
    "results_1 = evaluate_on_test_set(condition = CONDITION, epoch = BEST_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8846c-eee1-4741-aed9-5c8f6affc053",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Right Neural Foraminal Narrowing (captured by Sagittal T1 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4218e81a-33cb-4e71-9e76-c88f0a584b29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Loss: 0.5793\n",
      "  Accuracy: 79.40%\n",
      "  Class 0: Precision: 0.9313, Recall: 0.8465, F1-score: 0.8869\n",
      "  Class 1: Precision: 0.4592, Recall: 0.6377, F1-score: 0.5340\n",
      "  Class 2: Precision: 0.4182, Recall: 0.4340, F1-score: 0.4259\n"
     ]
    }
   ],
   "source": [
    "CONDITION = 'RightNeuralForaminalNarrowing'\n",
    "BEST_EPOCH = 5\n",
    "results_2 = evaluate_on_test_set(condition = CONDITION, epoch = BEST_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef2a4b-0a9f-4c01-a985-08e9546d231f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Left Subarticular Stenosis (captured by Axial T1 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "322bee56-42e4-4683-8b25-33e368e16c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Loss: 0.6665\n",
      "  Accuracy: 75.36%\n",
      "  Class 0: Precision: 0.8762, Recall: 0.8745, F1-score: 0.8754\n",
      "  Class 1: Precision: 0.4310, Recall: 0.4325, F1-score: 0.4318\n",
      "  Class 2: Precision: 0.4960, Recall: 0.5000, F1-score: 0.4980\n"
     ]
    }
   ],
   "source": [
    "CONDITION = 'LeftSubarticularStenosis'\n",
    "BEST_EPOCH = 1\n",
    "results_3 = evaluate_on_test_set(condition = CONDITION, epoch = BEST_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df602b68-34c5-4610-b89c-ce123bdf7c19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Right SubarticularStenosis (captured by Axial T1 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a38dcd1-118a-4e6a-a4c2-704d61f78744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Loss: 0.7375\n",
      "  Accuracy: 71.88%\n",
      "  Class 0: Precision: 0.8942, Recall: 0.8304, F1-score: 0.8611\n",
      "  Class 1: Precision: 0.3488, Recall: 0.3750, F1-score: 0.3614\n",
      "  Class 2: Precision: 0.4318, Recall: 0.5846, F1-score: 0.4967\n"
     ]
    }
   ],
   "source": [
    "CONDITION = 'RightSubarticularStenosis'\n",
    "BEST_EPOCH = 1\n",
    "results_4 = evaluate_on_test_set(condition = CONDITION, epoch = BEST_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258a6f77-33b5-405e-82d2-09e11b7daba5",
   "metadata": {},
   "source": [
    "# Results of the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c40058a1-725a-44d8-b194-e749c5d33632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_metrics_for_complete_set(results):\n",
    "    \n",
    "    n_examples = [r[0] for r in results]\n",
    "    losses     = [r[1] for r in results]\n",
    "    all_labels = sum([r[2] for r in results], [])\n",
    "    all_preds  = sum([r[3] for r in results], [])\n",
    "        \n",
    "    # Calculate accuracy, precision, and recall for the validation set\n",
    "    accuracy, precision, recall, f1 = accuracy_metrics(all_labels, all_preds)\n",
    "    avg_loss = sum([l * n for l, n in zip(n_examples, losses)]) / sum(n_examples)\n",
    "    \n",
    "    # Print validation metrics\n",
    "    print(f\"Validation Metrics:\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy * 100:.2f}%\")\n",
    "    for cls in range(num_classes):\n",
    "        print(f\"  Class {cls}: Precision: {precision[cls]:.4f}, Recall: {recall[cls]:.4f}, F1-score: {f1[cls]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f227c923-a1b2-44e5-b948-92ad26ca9cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Loss: 0.5847\n",
      "  Accuracy: 80.90%\n",
      "  Class 0: Precision: 0.9174, Recall: 0.8955, F1-score: 0.9063\n",
      "  Class 1: Precision: 0.4511, Recall: 0.4938, F1-score: 0.4715\n",
      "  Class 2: Precision: 0.4869, Recall: 0.5152, F1-score: 0.5007\n"
     ]
    }
   ],
   "source": [
    "results = [results_0, results_1, results_2, results_3, results_4]\n",
    "accuracy_metrics_for_complete_set(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [base-gpu.py310] (Local)",
   "language": "python",
   "name": "gcr.io_deeplearning-platform-release_base-gpu.py310_latest__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
